# 借即将发布的Qwen3.5（35B A3B？），教大家解读模型发布信息源

> 来源：https://www.bilibili.com/video/BV1RTcFzrERi | UP主：小天fotos | 时长：4:50

## 视频概述

本视频是一个实战教程，作者借Qwen3.5即将发布的时机，手把手教大家如何追踪开源模型的发布信息。从Twitter信息源到HuggingFace的Transformers仓库PR，再到使用GitHub Skill让AI帮忙分析代码，最终确认Qwen3.5全系列（包括35B A3B、多模态VL、9B稠密模型）都采用了Next架构，并且全部使用混合注意力机制。

## 核心主题

- **信息源追踪方法**：从Twitter → Transformers PR → 代码文件的完整链路
- **GitHub Skill的实战应用**：使用gh命令和AI分析PR代码变更
- **Qwen3.5架构揭秘**：全系列采用Next架构，混合注意力机制
- **模型参数确认**：35B A3B（不是30B）、9B稠密、多模态VL
- **验证方法**：从MD文档到Python配置文件的交叉验证

## 详细内容

### [00:00] 开场：Qwen3.5即将发布

**[00:00-00:15] 兴奋的消息**
> "大家好，今天非常高兴，晚上看到消息说Qwen3.5马上就要发了"

**[00:05-00:15] 视频主题**
有朋友让作者分享关于信息源的事，正好借这个机会教大家如何追踪开源模型发布信息。

### [00:15] 第一步：Twitter信息源

**[00:15-00:38] 从Twitter开始**
- 首先会在Twitter上关注
- 如果模型发布了，总有比作者更快的人会意识到
- 他们会从**Transformers的repo**上看到一个PR
- PR内容：要支持Qwen3.5了

**关键点：**
Twitter上的技术社区往往是最快的信息源

### [00:29] 第二步：找到HuggingFace Transformers PR

**[00:29-00:53] 顺藤摸瓜**
- 顺着Twitter信息找到HuggingFace Transformers仓库
- 在PR里找到Qwen3.5相关内容
- 到此为止，基本上就知道这个模型肯定要发了
- 基本上就是一两天内，PR就会通过
- 肯定就会快速发布

**[00:46-00:53] 其他工具也会跟进**
- vLLM、llama.cpp之类的也会赶快去更新
- 在他们的PR上肯定也能找到
- 但不要紧，我们看Transformers就行了

### [00:56] 第三步：传统方法 - 查看File Changes

**[00:56-01:08] 以前的做法**
- 会看这个File Changes
- 去找他看他这个MD里写什么
- 再看一下这些乱七八糟文件
- 当然以前看的都挺费劲的

**[01:08] 转折点**
> "现在我们不需要了"

### [01:08] 第四步：使用GitHub Skill自动分析

**[01:08-01:24] 新方法登场**
作者上次分享过的GitHub KB（知识库）技能：
- 让AI用`gh`命令去搜PR
- 搜索HuggingFace的repo
- 调查Qwen3.5相关的PR
- **关键是让他调查改动的代码**

**[01:24-01:28] 作者的需求**
> "我想知道模型，比如我现在最希望知道Qwen3.5是什么模型架构，然后有哪些新的参数的模型"

**[01:28-01:38] AI开始工作**
- AI就开始调查了
- 咱们不用看他这个中间的过程
- 咱们直接看他的结果

### [01:38] 第五步：AI分析结果 - 架构揭秘

**[01:38-01:47] 第一个发现：Next架构**
AI找到了：
> "Qwen3.5居然是用混合注意力机制，也就是说Next的架构"

**回顾：**
作者前几天分享过80B Coder Next

**[01:47-02:08] 第二个发现：三个模型**
1. **多模态模型**：Qwen3.5 VL
2. **稠密模型**：Qwen3.5 9B（一般9B模型都是稠密模型）
3. **混合专家模型**：35B A3B

**[02:08-02:12] 震惊的发现**
> "不是30B了，同志们！"

**[02:12-02:17] 质疑与验证**
> "这个是真的还是假的？这我们明后来看一下。我觉得搞不好是不是AI的幻觉？为什么不是30B了，变成35B了？"

**[02:17] 验证方法**
> "但是我们后面假怎么去验证他"

### [02:22] 第六步：确认架构细节

**[02:22-02:47] 已知信息**
- Qwen3.5和Qwen3.5 MOE都用了Next架构

**[02:27-02:39] 追问AI**
作者继续追问：
- 35B A3B是不是Next架构？
- 是不是全部都是混合注意力？
- 在哪？让他帮我找到确切的Python文件

### [02:42] 第七步：从MD文档到Python文件

**[02:42-02:50] 作者的经验**
> "一般我的感觉是MD文档可能不一定真实"

**[02:44-02:50] 关键洞察**
> "有时候MD文档上出现的模型名不一定是真的会有，但是Python文件里是一定会有的"

**这是非常重要的验证方法！**

### [02:50] 第八步：AI读取配置文件

**[02:50-03:04] AI的工作流程**
- 让他调查
- 他就会去搜代码
- 使用命令把代码全部读一遍
- 读取`Qwen35MOEConfig`
- 发现它是从`Qwen2Config`继承的

**[03:04-03:06] 结论**
> "所以他就是一个Next架构"

### [03:06] 第九步：确认35B A3B的存在

**[03:06-03:22] 最终确认**
- 确实是有35B A3B
- 他是一个Next架构
- 也就是说Qwen3.5版本
- 已经不再会有过去的MOE架构
- **所有都是混合注意力**

**[03:16-03:22] 作者的评价**
> "这个很厉害"

### [03:22] 第十步：查看Python文件来源

**[03:22-03:33] 验证来源**
- AI给你找到这个Python文件
- 找一下这个文件：35MOE
- 作者说："我不看代码，我就看他的解读就行了"

### [03:33] 第十一步：确认多模态模型架构

**[03:33-03:46] 继续追问**
> "然后问他多模态模型是不是Next架构，看他的回答"

**[03:44-03:46] 答案揭晓**
> "多模态模型也是Next架构！"

**[03:46-03:55] 震撼的结论**
> "哇的天！Qwen3.5 VL也是Next架构！Qwen彻底全部迭代到这个Next架构上了，以前架构彻底不用了"

### [03:55] 架构统一的意义

**[03:55-04:00] 作者的评价**
> "我觉得这也是好事，这个架构是真的挺快的"

**[04:00-04:07] 参数修正**
> "也就是说以前的Qwen3 VL 30B A3B，现在应该改成35B A3B了"

### [04:07] 多模态能力确认

**[04:07-04:21] OMI（全模态）支持**
- OMI没有
- Qwen3.5 VL还是只支持图像、视频
- 没有Audio
- 所以是没有更新的

**[04:17-04:21] 需要继续等待**
> "Qwen3.5 VL没有OMI的东西，OMI我们可能还得再等一等"

### [04:23] 总结：信息追踪方法论

**[04:23-04:35] 完整流程回顾**
今天就是给大家讲一下：
1. 怎么样去从一个信息源
2. 一直追溯到代码层面
3. 包括对AI的追问
4. 最终能获得到一个准确的信息

**[04:35-04:39] 信任AI的判断**
> "这个应该不会假吧？我不想去读代码，我就信他吧，他不会读错"

### [04:39] 结尾：期待Qwen3.5发布

**[04:39-04:50] 最后的期待**
- 大家胜利代吧（等待吧）
- Qwen3.5更新第一时间，我一定回去测的
- **35B非常好的一个尺寸**
- Nice！

## 重要概念与术语

| 术语 | 解释 |
|------|------|
| **Transformers PR** | HuggingFace Transformers库的Pull Request，模型发布前会提交PR添加支持 |
| **Next架构** | Qwen的新一代架构，采用混合注意力机制，性能更快 |
| **混合注意力机制** | Next架构的核心特性，结合了不同类型的注意力机制 |
| **35B A3B** | Qwen3.5的混合专家模型，35B总参数，A3B激活参数 |
| **稠密模型** | 所有参数都参与计算的模型，如9B模型 |
| **MOE（混合专家）** | Mixture of Experts，只激活部分专家参数的架构 |
| **gh命令** | GitHub CLI工具，可以在命令行操作GitHub |
| **GitHub Skill** | 作者开发的技能，让AI使用gh命令分析GitHub仓库 |
| **Config文件** | Python配置文件，定义模型架构参数，比MD文档更可靠 |
| **OMI（全模态）** | 支持图像、视频、音频的全模态能力 |
| **vLLM** | 高性能LLM推理引擎 |
| **llama.cpp** | 本地运行大模型的C++工具 |

## 关键要点

1. **信息追踪链路**：Twitter → Transformers PR → File Changes → Python Config文件

2. **GitHub Skill的威力**：让AI自动分析PR代码变更，大大提高效率

3. **验证方法的重要性**：MD文档可能不准确，Python配置文件才是真相

4. **Qwen3.5全系列架构统一**：全部采用Next架构，混合注意力机制

5. **参数修正**：从30B A3B变成35B A3B，参数规模有所增加

6. **三个模型确认**：
   - Qwen3.5 9B（稠密模型）
   - Qwen3.5 35B A3B（混合专家）
   - Qwen3.5 VL（多模态）

7. **架构继承关系**：Qwen35MOEConfig继承自Qwen2Config，证明是Next架构

8. **OMI暂未支持**：Qwen3.5 VL仍只支持图像和视频，音频需要继续等待

9. **35B是好尺寸**：作者认为35B是非常适合的参数规模

10. **AI辅助分析的可靠性**：通过追问和交叉验证，AI能准确分析代码

## 总结与建议

### 方法论价值

本视频最大的价值在于展示了一套完整的**开源模型信息追踪方法论**：

1. **信息源层**：Twitter技术社区（最快）
2. **代码层**：HuggingFace Transformers PR（官方）
3. **验证层**：Python配置文件（最可靠）
4. **工具层**：GitHub Skill + AI分析（高效）

### GitHub Skill的实战应用

作者展示了如何使用自己开发的GitHub Skill：
- 使用`gh`命令搜索PR
- 让AI分析代码变更
- 追问具体的架构细节
- 找到确切的Python文件
- 读取配置文件验证

这种方法比手动查看代码高效得多，而且AI能快速定位关键信息。

### 验证方法的智慧

**关键洞察：MD文档 < Python配置文件**

- MD文档可能包含计划中但未实现的模型
- Python配置文件是实际代码，不会骗人
- 通过继承关系（如`Qwen35MOEConfig`继承`Qwen2Config`）可以确认架构

### Qwen3.5的技术突破

**架构统一的意义：**
- 全系列采用Next架构
- 混合注意力机制性能更好
- 放弃旧的MOE架构，技术路线更清晰
- 35B A3B参数规模适中，适合实际应用

### 行动建议

1. **学习信息追踪方法**：
   - 关注Twitter技术社区
   - 监控HuggingFace Transformers PR
   - 学会使用GitHub CLI

2. **开发或使用GitHub Skill**：
   - 让AI帮你分析代码
   - 提高信息获取效率
   - 减少手动阅读代码的时间

3. **建立验证习惯**：
   - 不要只看MD文档
   - 深入到Python配置文件
   - 交叉验证多个信息源

4. **关注Qwen3.5发布**：
   - 第一时间测试35B A3B
   - 体验Next架构的性能提升
   - 评估是否适合自己的应用场景

5. **期待OMI支持**：
   - 当前VL只支持图像和视频
   - 音频支持需要继续等待
   - 关注后续更新

### 对开发者的启示

- **信息获取能力是核心竞争力**：谁能更快获取准确信息，谁就能抢占先机
- **工具化思维**：开发Skill让AI帮你工作，而不是手动做重复劳动
- **验证思维**：不要轻信单一信息源，要交叉验证
- **代码是真相**：最终还是要看代码，配置文件不会骗人

**最终期待：35B A3B，非常好的一个尺寸，Nice！**
