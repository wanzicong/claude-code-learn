# 借即将发布的Qwen3.5（35B A3B?），教大家解读模型发布信息源

> 来源：https://www.bilibili.com/video/BV1RTcFzrERi | UP主：小天fotos | 时长：4:50

## 视频概述

本视频教大家如何从信息源追踪AI模型发布信息，以即将发布的Qwen3.5为例，演示如何通过Twitter、GitHub PR、Transformers代码库等渠道，结合AI工具深入解读模型架构和参数配置，最终确认Qwen3.5全系列采用Next架构和混合注意力机制。

## 核心主题

- AI模型发布信息的追踪方法
- 如何从GitHub PR获取模型技术细节
- 使用AI工具（GitHub KB）辅助代码分析
- Qwen3.5系列模型架构解读
- 混合注意力机制（Hybrid Attention）的应用

## 详细内容

### [00:00] 视频引入 - Qwen3.5即将发布

- 晚上看到消息说Qwen3.5马上就要发布
- 有朋友希望分享关于信息源的追踪方法
- 本视频将演示如何追踪开源模型发布的信息

### [00:15] 第一步：从Twitter获取初始信息

- 首先会在Twitter上关注相关动态
- 总有比自己更快的人会发现模型发布的迹象
- 他们会从Transformers的GitHub仓库中发现PR（Pull Request）
- PR中会显示"我要支持Qwen3.5了"

### [00:29] 第二步：追踪到Hugging Face Transformers的PR

- 顺着Twitter信息找到Hugging Face Transformers仓库的PR
- 在PR里找到Qwen3.5的相关信息
- 基本上可以确定模型肯定要发布，通常在一两天内PR就会通过
- 其他库（如vLLM、llama.cpp等）也会快速更新

### [00:56] 传统方法：查看File Changes

- 以前的做法是查看PR的File Changes
- 查看Markdown文档里写了什么
- 查看各种配置文件
- 但这种方法比较费劲

### [01:08] 新方法：使用GitHub KB + AI工具

- 现在使用GitHub KB工具，通过GH命令搜索PR
- 让AI搜索Hugging Face Transformers仓库中Qwen3.5相关的PR
- 关键是让AI调查改动的代码
- 想知道模型的架构、有哪些新的参数

### [01:41] AI分析结果：Qwen3.5采用混合注意力机制

- AI调查发现Qwen3.5使用混合注意力机制（Hybrid Attention）
- 也就是说采用Next架构
- 之前分享过80B Code Next模型

### [01:53] Qwen3.5系列模型配置

**发现的模型版本：**

1. **Qwen3.5多模态模型（VL）**
   - 采用Next架构
   - 支持图像和视频
   - 暂不支持Audio（OMI功能）

2. **Qwen3.5稠密模型**
   - 9B参数版本
   - 一般9B模型都是稠密模型

3. **Qwen3.5混合专家模型（MoE）**
   - **35B A3B**（不是30B！）
   - 采用Next架构
   - 混合注意力机制

### [02:08] 验证35B A3B的真实性

- 对于35B A3B这个参数感到惊讶（原本以为是30B）
- 需要验证这个信息是否准确
- 怀疑是否是AI的幻觉

### [02:20] 深入验证：查找配置文件

**验证方法：**
- MD文档可能不一定真实
- 有时候MD文档上出现的模型名不一定是真的会有
- **但是配置文件（.py文件）里一定会有**
- 让AI去搜索代码进行验证

### [02:53] 代码层面的确认

**AI的调查过程：**
1. 使用命令读取所有相关代码
2. 找到`Qwen35MoEConfig`配置文件
3. 发现它继承自`Qwen2Config`
4. 确认是Next架构

**最终确认：**
- 确实存在35B A3B版本
- 它是Next架构
- Qwen3.5全系列不再使用过去的MoE架构
- **所有模型都采用混合注意力机制**

### [03:26] 多模态模型的架构确认

- 询问AI多模态模型是否也是Next架构
- 得到确认：Qwen3.5 VL也是Next架构
- Qwen彻底全部迁移到Next架构
- 以前的架构彻底不用了

### [03:57] 关于OMI功能的说明

- Qwen3 VL、30B A3B现在应该改成35B A3B
- Qwen3.5 VL只支持图像和视频，没有Audio
- OMI（全模态）功能还需要再等一等

### [04:23] 总结：信息追踪方法论

**完整流程：**
1. 从Twitter等社交媒体获取初始信息
2. 追踪到GitHub PR
3. 使用AI工具分析代码变更
4. 通过配置文件验证信息真实性
5. 深入追问AI获取准确信息

**关键点：**
- 不要只看MD文档，要看配置文件
- 利用AI工具辅助代码分析
- 追溯到代码层面才能获得准确信息

## 重要概念与术语

| 术语 | 解释 |
|------|------|
| **Next架构** | Qwen3.5系列采用的新架构，相比之前的架构更快 |
| **混合注意力机制（Hybrid Attention）** | Qwen3.5全系列采用的注意力机制，是Next架构的核心特性 |
| **MoE（Mixture of Experts）** | 混合专家模型，通过多个专家网络提升模型能力 |
| **35B A3B** | Qwen3.5 MoE版本的参数配置，总参数35B，激活参数3B |
| **PR（Pull Request）** | GitHub上的代码合并请求，是追踪模型发布的重要信息源 |
| **Transformers** | Hugging Face的开源库，大多数模型会首先在这里支持 |
| **GitHub KB** | 用于分析GitHub仓库的AI工具，可以搜索PR和分析代码 |
| **OMI（Omni-Modal）** | 全模态功能，支持文本、图像、视频、音频等多种模态 |
| **稠密模型** | 相对于MoE，所有参数都参与计算的传统模型架构 |

## 关键要点

1. **信息源追踪路径**：Twitter → GitHub PR → Transformers代码库 → 配置文件
2. **Qwen3.5全系列采用Next架构**，彻底放弃了之前的架构
3. **35B A3B是真实存在的**，不是30B，通过配置文件得到验证
4. **混合注意力机制**成为Qwen3.5全系列的标配
5. **配置文件比MD文档更可靠**，是验证信息真实性的关键
6. **AI工具（GitHub KB）**可以大大提升代码分析效率
7. **Qwen3.5 VL暂不支持Audio**，OMI功能还需等待
8. **35B是一个非常好的尺寸**，值得期待

## 总结与建议

### 方法论总结

本视频展示了一套完整的AI模型信息追踪方法论：

1. **多渠道信息获取**：关注Twitter、GitHub等平台的动态
2. **源头追溯**：从社交媒体追踪到代码仓库
3. **工具辅助**：使用AI工具（如GitHub KB）分析代码
4. **深度验证**：通过配置文件验证信息真实性
5. **持续追问**：对AI进行多轮追问，获取准确信息

### 实践建议

- **关注Hugging Face Transformers的PR**：这是获取模型发布信息的第一手来源
- **学会使用AI工具分析代码**：可以大大提升效率，无需手动阅读大量代码
- **重视配置文件**：配置文件（.py）比文档（.md）更可靠
- **建立信息验证机制**：不要轻信单一来源，要通过代码层面验证
- **保持关注**：Qwen3.5发布后第一时间测试，35B A3B是一个值得期待的尺寸

### 技术展望

- Qwen3.5全系列采用Next架构和混合注意力机制，预示着更快的推理速度
- 35B A3B的参数配置在性能和效率之间取得了良好平衡
- OMI全模态功能虽然暂未支持，但值得期待后续更新
