#!/usr/bin/env python3
"""
Claude Code å¯¹è¯è®°å½•åŒæ­¥åˆ° GitHub çš„æ ¸å¿ƒè„šæœ¬ã€‚

åŠŸèƒ½ï¼š
- ä» ~/.claude/projects/ è¯»å– JSONL å¯¹è¯è®°å½•
- ä½¿ç”¨æœ¬åœ°æœºå™¨ç ä½œä¸ºé¡¹ç›®æ ‡è¯†
- ç»“æ„åŒ–è¾“å‡ºä¸º Markdown æ–‡ä»¶
- æ”¯æŒå¢é‡/å…¨é‡åŒæ­¥
- ä½¿ç”¨ gh/git å‘½ä»¤æ¨é€åˆ° GitHub

ç”¨æ³•ï¼š
  python sync_conversations.py --mode full     # å…¨é‡åŒæ­¥
  python sync_conversations.py --mode incremental  # å¢é‡åŒæ­¥ï¼ˆé»˜è®¤ï¼‰
  python sync_conversations.py --init           # åˆå§‹åŒ–ä»“åº“
  python sync_conversations.py --status         # æŸ¥çœ‹åŒæ­¥çŠ¶æ€
"""

import argparse
import json
import os
import platform
import re
import subprocess
import sys
import hashlib
import shutil
from datetime import datetime, timezone
from pathlib import Path


# ============================================================
# é…ç½®
# ============================================================

CLAUDE_DIR = Path.home() / ".claude"
PROJECTS_DIR = CLAUDE_DIR / "projects"
SYNC_STATE_FILE = CLAUDE_DIR / ".sync-state.json"
DEFAULT_REPO_PREFIX = "claude-conversations"


# ============================================================
# å·¥å…·å‡½æ•°
# ============================================================

def run_cmd(cmd, cwd=None, check=True, capture=True):
    """æ‰§è¡Œå‘½ä»¤å¹¶è¿”å›è¾“å‡ºã€‚"""
    result = subprocess.run(
        cmd, cwd=cwd, capture_output=capture, text=True,
        shell=(platform.system() == "Windows"), check=False
    )
    if check and result.returncode != 0:
        stderr = result.stderr.strip() if result.stderr else ""
        raise RuntimeError(f"å‘½ä»¤å¤±è´¥: {' '.join(cmd)}\n{stderr}")
    return result


def get_machine_id():
    """è·å–æœ¬åœ°æœºå™¨å”¯ä¸€æ ‡è¯†ç ã€‚"""
    system = platform.system()
    try:
        if system == "Windows":
            r = run_cmd(
                ["powershell", "-Command",
                 "Get-CimInstance -ClassName Win32_ComputerSystemProduct | Select-Object -ExpandProperty UUID"],
                check=True
            )
            return r.stdout.strip()
        elif system == "Darwin":
            r = run_cmd(
                ["ioreg", "-rd1", "-c", "IOPlatformExpertDevice"],
                check=True
            )
            for line in r.stdout.splitlines():
                if "IOPlatformUUID" in line:
                    return line.split('"')[-2]
        else:  # Linux
            uuid_path = Path("/sys/class/dmi/id/product_uuid")
            if uuid_path.exists():
                return uuid_path.read_text().strip()
            machine_id_path = Path("/etc/machine-id")
            if machine_id_path.exists():
                return machine_id_path.read_text().strip()
    except Exception:
        pass
    # å›é€€ï¼šç”¨ä¸»æœºåç”Ÿæˆå“ˆå¸Œ
    fallback = f"{platform.node()}-{platform.machine()}-{platform.system()}"
    return hashlib.sha256(fallback.encode()).hexdigest()[:36]


def get_machine_id_short(machine_id):
    """è·å–æœºå™¨ç çš„çŸ­æ ‡è¯†ï¼ˆå‰8ä½ï¼‰ã€‚"""
    return machine_id.replace("-", "")[:8].upper()


def gh_available():
    """æ£€æŸ¥ gh CLI æ˜¯å¦å¯ç”¨ä¸”å·²è®¤è¯ã€‚"""
    try:
        r = run_cmd(["gh", "auth", "status"], check=False)
        return r.returncode == 0
    except FileNotFoundError:
        return False


def repo_exists_on_github(repo_name):
    """æ£€æŸ¥ GitHub ä¸Šæ˜¯å¦å·²å­˜åœ¨è¯¥ä»“åº“ã€‚"""
    r = run_cmd(["gh", "repo", "view", repo_name], check=False)
    return r.returncode == 0


# ============================================================
# å¯¹è¯è§£æ
# ============================================================

def parse_jsonl_file(filepath):
    """è§£æå•ä¸ª JSONL å¯¹è¯æ–‡ä»¶ï¼Œè¿”å›ç»“æ„åŒ–æ¶ˆæ¯åˆ—è¡¨ã€‚"""
    messages = []
    with open(filepath, "r", encoding="utf-8") as f:
        for line_num, line in enumerate(f, 1):
            line = line.strip()
            if not line:
                continue
            try:
                record = json.loads(line)
            except json.JSONDecodeError:
                continue

            record_type = record.get("type", "")

            if record_type == "user":
                msg = record.get("message", {})
                content = msg.get("content", "")
                tool_results = []
                if isinstance(content, list):
                    text_parts = []
                    for item in content:
                        if not isinstance(item, dict):
                            continue
                        itype = item.get("type", "")
                        if itype == "text":
                            text_parts.append(item.get("text", ""))
                        elif itype == "tool_result":
                            tr_content = item.get("content", "")
                            if isinstance(tr_content, list):
                                tr_text = "\n".join(
                                    sub.get("text", "") for sub in tr_content
                                    if isinstance(sub, dict) and sub.get("type") == "text"
                                )
                            else:
                                tr_text = str(tr_content) if tr_content else ""
                            if tr_text:
                                is_err = item.get("is_error", False)
                                tool_results.append({
                                    "content": tr_text[:500] + ("..." if len(tr_text) > 500 else ""),
                                    "is_error": is_err,
                                })
                    content = "\n".join(text_parts)
                messages.append({
                    "type": "user",
                    "uuid": record.get("uuid", ""),
                    "timestamp": record.get("timestamp", ""),
                    "content": content,
                    "tool_results": tool_results,
                    "cwd": record.get("cwd", ""),
                })

            elif record_type == "assistant":
                msg = record.get("message", {})
                content_parts = msg.get("content", [])
                text_parts = []
                tool_uses = []
                thinking = []

                if isinstance(content_parts, str):
                    text_parts.append(content_parts)
                elif isinstance(content_parts, list):
                    for part in content_parts:
                        if not isinstance(part, dict):
                            continue
                        ptype = part.get("type", "")
                        if ptype == "text":
                            text_parts.append(part.get("text", ""))
                        elif ptype == "thinking":
                            thinking.append(part.get("thinking", ""))
                        elif ptype == "tool_use":
                            tool_uses.append({
                                "name": part.get("name", ""),
                                "input_summary": _summarize_tool_input(part.get("input", {}))
                            })
                        elif ptype == "server_tool_use":
                            tool_uses.append({
                                "name": part.get("name", ""),
                                "input_summary": _summarize_tool_input(part.get("input", {}))
                            })

                messages.append({
                    "type": "assistant",
                    "uuid": record.get("uuid", ""),
                    "timestamp": record.get("timestamp", ""),
                    "model": msg.get("model", "unknown"),
                    "content": "\n".join(text_parts),
                    "tool_uses": tool_uses,
                    "thinking_summary": thinking[0][:200] + "..." if thinking and len(thinking[0]) > 200 else (thinking[0] if thinking else ""),
                    "usage": msg.get("usage", {}),
                })

            elif record_type == "summary":
                messages.append({
                    "type": "summary",
                    "summary": record.get("summary", ""),
                    "timestamp": record.get("timestamp", ""),
                })

    return messages


def _summarize_tool_input(input_data):
    """ç®€è¦æ¦‚è¿°å·¥å…·è°ƒç”¨çš„è¾“å…¥å‚æ•°ã€‚"""
    if not input_data:
        return ""
    if isinstance(input_data, str):
        return input_data[:100]
    if isinstance(input_data, dict):
        parts = []
        for k, v in input_data.items():
            v_str = str(v)
            if len(v_str) > 80:
                v_str = v_str[:80] + "..."
            parts.append(f"{k}: {v_str}")
        return "; ".join(parts[:5])
    return str(input_data)[:200]


def format_conversation_md(session_id, messages, project_path):
    """å°†å¯¹è¯æ¶ˆæ¯æ ¼å¼åŒ–ä¸º Markdown æ–‡ä»¶å†…å®¹ã€‚"""
    lines = []

    # æå–å…ƒä¿¡æ¯
    first_ts = ""
    last_ts = ""
    model = "unknown"
    summary_text = ""
    total_input_tokens = 0
    total_output_tokens = 0

    for m in messages:
        ts = m.get("timestamp", "")
        if ts and not first_ts:
            first_ts = ts
        if ts:
            last_ts = ts
        if m.get("type") == "assistant" and m.get("model", "unknown") != "unknown":
            model = m["model"]
        if m.get("type") == "summary":
            summary_text = m.get("summary", "")
        usage = m.get("usage", {})
        total_input_tokens += usage.get("input_tokens", 0)
        total_output_tokens += usage.get("output_tokens", 0)

    # æ ‡é¢˜
    title = summary_text if summary_text else f"å¯¹è¯ {session_id[:8]}"
    lines.append(f"# {title}")
    lines.append("")

    # å…ƒä¿¡æ¯è¡¨
    lines.append("| å±æ€§ | å€¼ |")
    lines.append("|------|-----|")
    lines.append(f"| ä¼šè¯ID | `{session_id}` |")
    lines.append(f"| é¡¹ç›®è·¯å¾„ | `{project_path}` |")
    lines.append(f"| æ¨¡å‹ | `{model}` |")
    lines.append(f"| å¼€å§‹æ—¶é—´ | {_format_ts(first_ts)} |")
    lines.append(f"| ç»“æŸæ—¶é—´ | {_format_ts(last_ts)} |")
    if total_input_tokens or total_output_tokens:
        lines.append(f"| Tokenç”¨é‡ | è¾“å…¥: {total_input_tokens:,} / è¾“å‡º: {total_output_tokens:,} |")
    lines.append("")
    lines.append("---")
    lines.append("")

    # å¯¹è¯å†…å®¹
    msg_count = 0
    for m in messages:
        if m["type"] == "user":
            content = m.get("content", "")
            tool_results = m.get("tool_results", [])

            # è·³è¿‡æ—¢æ²¡æœ‰æ–‡æœ¬ä¹Ÿæ²¡æœ‰å·¥å…·ç»“æœçš„ç©ºæ¶ˆæ¯
            if not content.strip() and not tool_results:
                continue

            msg_count += 1
            lines.append(f"## ğŸ‘¤ ç”¨æˆ· #{msg_count}")
            lines.append(f"*{_format_ts(m.get('timestamp', ''))}*")
            lines.append("")

            if content.strip():
                lines.append(content)
                lines.append("")

            # å·¥å…·è¿”å›ç»“æœ
            if tool_results:
                lines.append("<details>")
                lines.append(f"<summary>ğŸ“‹ å·¥å…·è¿”å›ç»“æœ ({len(tool_results)}æ¡)</summary>")
                lines.append("")
                for tr in tool_results:
                    err_tag = " âŒ é”™è¯¯" if tr.get("is_error") else ""
                    lines.append(f"**ç»“æœ{err_tag}:**")
                    lines.append("```")
                    lines.append(tr.get("content", ""))
                    lines.append("```")
                    lines.append("")
                lines.append("</details>")
                lines.append("")

        elif m["type"] == "assistant":
            lines.append(f"## ğŸ¤– åŠ©æ‰‹")
            lines.append(f"*{_format_ts(m.get('timestamp', ''))} | æ¨¡å‹: {m.get('model', 'unknown')}*")
            lines.append("")

            # æ€è€ƒè¿‡ç¨‹ï¼ˆæŠ˜å ï¼‰
            if m.get("thinking_summary"):
                lines.append("<details>")
                lines.append("<summary>ğŸ’­ æ€è€ƒè¿‡ç¨‹</summary>")
                lines.append("")
                lines.append(m["thinking_summary"])
                lines.append("")
                lines.append("</details>")
                lines.append("")

            # å›å¤å†…å®¹
            if m.get("content"):
                lines.append(m["content"])
                lines.append("")

            # å·¥å…·è°ƒç”¨ï¼ˆæŠ˜å ï¼‰
            if m.get("tool_uses"):
                lines.append("<details>")
                lines.append(f"<summary>ğŸ”§ å·¥å…·è°ƒç”¨ ({len(m['tool_uses'])}æ¬¡)</summary>")
                lines.append("")
                for tu in m["tool_uses"]:
                    lines.append(f"- **{tu['name']}**: {tu.get('input_summary', '')}")
                lines.append("")
                lines.append("</details>")
                lines.append("")

        elif m["type"] == "summary":
            pass  # å·²åœ¨æ ‡é¢˜ä¸­ä½¿ç”¨

        lines.append("---")
        lines.append("")

    return "\n".join(lines)


def _format_ts(ts_str):
    """æ ¼å¼åŒ– ISO æ—¶é—´æˆ³ä¸ºå¯è¯»æ ¼å¼ã€‚"""
    if not ts_str:
        return "æœªçŸ¥"
    try:
        dt = datetime.fromisoformat(ts_str.replace("Z", "+00:00"))
        return dt.strftime("%Y-%m-%d %H:%M:%S UTC")
    except (ValueError, TypeError):
        return ts_str


# ============================================================
# åŒæ­¥çŠ¶æ€ç®¡ç†
# ============================================================

def load_sync_state():
    """åŠ è½½åŒæ­¥çŠ¶æ€ã€‚"""
    if SYNC_STATE_FILE.exists():
        with open(SYNC_STATE_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    return {"synced_files": {}, "last_sync": None}


def save_sync_state(state):
    """ä¿å­˜åŒæ­¥çŠ¶æ€ã€‚"""
    state["last_sync"] = datetime.now(timezone.utc).isoformat()
    with open(SYNC_STATE_FILE, "w", encoding="utf-8") as f:
        json.dump(state, f, ensure_ascii=False, indent=2)


def get_file_hash(filepath):
    """è·å–æ–‡ä»¶çš„ MD5 å“ˆå¸Œå€¼ã€‚"""
    h = hashlib.md5()
    with open(filepath, "rb") as f:
        for chunk in iter(lambda: f.read(8192), b""):
            h.update(chunk)
    return h.hexdigest()


# ============================================================
# é¡¹ç›®æ‰«æ
# ============================================================

def scan_projects():
    """æ‰«ææ‰€æœ‰é¡¹ç›®å’Œå¯¹è¯æ–‡ä»¶ã€‚"""
    if not PROJECTS_DIR.exists():
        print(f"é”™è¯¯: æœªæ‰¾åˆ° Claude Code é¡¹ç›®ç›®å½•: {PROJECTS_DIR}")
        sys.exit(1)

    projects = {}
    for project_dir in PROJECTS_DIR.iterdir():
        if not project_dir.is_dir():
            continue

        project_name = project_dir.name
        jsonl_files = list(project_dir.glob("*.jsonl"))

        if not jsonl_files:
            continue

        # æ”¶é›†é¡¹ç›®çº§åˆ«çš„é¢å¤–æ–‡ä»¶ï¼ˆjson ç´¢å¼•ç­‰ï¼‰
        extra_files = []
        for jf in project_dir.glob("*.json"):
            extra_files.append(jf)

        # æ”¶é›† subagents ç›®å½•
        subagents_dir = project_dir / "subagents"

        projects[project_name] = {
            "path": project_dir,
            "sessions": [],
            "extra_files": extra_files,
            "has_subagents": subagents_dir.exists() and subagents_dir.is_dir(),
        }

        for jf in jsonl_files:
            session_id = jf.stem
            # æ£€æŸ¥è¯¥ä¼šè¯æ˜¯å¦æœ‰å­ç›®å½•ï¼ˆtool-results ç­‰ï¼‰
            session_subdir = project_dir / session_id
            projects[project_name]["sessions"].append({
                "id": session_id,
                "file": jf,
                "size": jf.stat().st_size,
                "mtime": jf.stat().st_mtime,
                "has_subdir": session_subdir.exists() and session_subdir.is_dir(),
            })

    return projects


def decode_project_path(encoded_name):
    """å°†ç¼–ç çš„é¡¹ç›®ç›®å½•åè¿˜åŸä¸ºåŸå§‹è·¯å¾„ã€‚"""
    # C--Users-13608 -> C:\Users\13608
    path = encoded_name
    # è¿˜åŸé©±åŠ¨å™¨å·: C-- -> C:
    path = re.sub(r'^([A-Za-z])--', r'\1:/', path)
    # è¿˜åŸè·¯å¾„åˆ†éš”ç¬¦
    path = path.replace("-", "/")
    return path


def sanitize_dirname(name):
    """å°†é¡¹ç›®è·¯å¾„è½¬ä¸ºå®‰å…¨çš„ç›®å½•åã€‚"""
    # ç§»é™¤é©±åŠ¨å™¨å·å‰ç¼€ï¼Œä¿ç•™æœ‰æ„ä¹‰çš„è·¯å¾„
    name = re.sub(r'^[A-Za-z]--', '', name)
    # æ›¿æ¢ä¸å®‰å…¨å­—ç¬¦
    name = re.sub(r'[<>:"/\\|?*]', '-', name)
    # åˆå¹¶è¿ç»­çš„è¿å­—ç¬¦
    name = re.sub(r'-+', '-', name)
    return name.strip('-') or "default"


# ============================================================
# æ ¸å¿ƒåŒæ­¥é€»è¾‘
# ============================================================

def init_repo(machine_id, repo_name=None):
    """åˆå§‹åŒ– GitHub ä»“åº“ã€‚"""
    if not gh_available():
        print("é”™è¯¯: gh CLI æœªå®‰è£…æˆ–æœªè®¤è¯ã€‚è¯·å…ˆè¿è¡Œ 'gh auth login'")
        sys.exit(1)

    short_id = get_machine_id_short(machine_id)
    if not repo_name:
        repo_name = f"{DEFAULT_REPO_PREFIX}-{short_id}"

    # è·å–å½“å‰ GitHub ç”¨æˆ·å
    r = run_cmd(["gh", "api", "user", "-q", ".login"])
    username = r.stdout.strip()
    full_repo = f"{username}/{repo_name}"

    print(f"æœºå™¨ç : {machine_id}")
    print(f"çŸ­æ ‡è¯†: {short_id}")
    print(f"ä»“åº“å: {full_repo}")

    # æ£€æŸ¥ä»“åº“æ˜¯å¦å·²å­˜åœ¨
    if repo_exists_on_github(full_repo):
        print(f"ä»“åº“å·²å­˜åœ¨: {full_repo}")
        return full_repo

    # åˆ›å»ºç§æœ‰ä»“åº“
    print(f"æ­£åœ¨åˆ›å»ºç§æœ‰ä»“åº“: {full_repo}")
    run_cmd([
        "gh", "repo", "create", repo_name,
        "--private",
        "--description", f"Claude Code å¯¹è¯è®°å½• - æœºå™¨ {short_id}",
    ])
    print(f"ä»“åº“åˆ›å»ºæˆåŠŸ: {full_repo}")
    return full_repo


def sync(mode="incremental", repo_name=None):
    """æ‰§è¡ŒåŒæ­¥æ“ä½œã€‚"""
    if not gh_available():
        print("é”™è¯¯: gh CLI æœªå®‰è£…æˆ–æœªè®¤è¯ã€‚è¯·å…ˆè¿è¡Œ 'gh auth login'")
        sys.exit(1)

    machine_id = get_machine_id()
    short_id = get_machine_id_short(machine_id)

    if not repo_name:
        repo_name = f"{DEFAULT_REPO_PREFIX}-{short_id}"

    # è·å–ç”¨æˆ·å
    r = run_cmd(["gh", "api", "user", "-q", ".login"])
    username = r.stdout.strip()
    full_repo = f"{username}/{repo_name}"

    # ç¡®ä¿ä»“åº“å­˜åœ¨
    if not repo_exists_on_github(full_repo):
        print(f"ä»“åº“ä¸å­˜åœ¨ï¼Œæ­£åœ¨åˆå§‹åŒ–...")
        init_repo(machine_id, repo_name)

    # å‡†å¤‡æœ¬åœ°å·¥ä½œç›®å½•
    work_dir = CLAUDE_DIR / ".sync-workdir"
    repo_dir = work_dir / repo_name

    if not repo_dir.exists():
        print(f"æ­£åœ¨å…‹éš†ä»“åº“...")
        work_dir.mkdir(parents=True, exist_ok=True)
        run_cmd(["gh", "repo", "clone", full_repo, str(repo_dir)], check=False)
        if not (repo_dir / ".git").exists():
            # ä»“åº“ä¸ºç©ºï¼Œæ‰‹åŠ¨åˆå§‹åŒ–
            repo_dir.mkdir(parents=True, exist_ok=True)
            run_cmd(["git", "init"], cwd=str(repo_dir))
            run_cmd(["git", "remote", "add", "origin",
                      f"https://github.com/{full_repo}.git"], cwd=str(repo_dir))
    else:
        # æ‹‰å–æœ€æ–°
        run_cmd(["git", "pull", "--rebase"], cwd=str(repo_dir), check=False)

    # åŠ è½½åŒæ­¥çŠ¶æ€
    state = load_sync_state()
    synced_files = state.get("synced_files", {})

    # æ‰«æé¡¹ç›®
    projects = scan_projects()
    total_sessions = sum(len(p["sessions"]) for p in projects.values())
    print(f"å‘ç° {len(projects)} ä¸ªé¡¹ç›®ï¼Œå…± {total_sessions} ä¸ªå¯¹è¯")

    # åˆ›å»º README
    readme_path = repo_dir / "README.md"
    readme_content = _generate_readme(machine_id, short_id, projects)
    readme_path.write_text(readme_content, encoding="utf-8")

    # å¤„ç†æ¯ä¸ªé¡¹ç›®
    synced_count = 0
    skipped_count = 0

    for project_name, project_info in projects.items():
        project_display = sanitize_dirname(project_name)
        project_out_dir = repo_dir / project_display
        project_out_dir.mkdir(parents=True, exist_ok=True)

        # åŸå§‹æ–‡ä»¶å­˜æ”¾ç›®å½•
        raw_dir = project_out_dir / "raw"
        raw_dir.mkdir(parents=True, exist_ok=True)

        # å¤åˆ¶é¡¹ç›®çº§åˆ«çš„é¢å¤–æ–‡ä»¶ï¼ˆsessions-index.json ç­‰ï¼‰
        for ef in project_info.get("extra_files", []):
            dst = raw_dir / ef.name
            shutil.copy2(ef, dst)

        # å¤åˆ¶ subagents ç›®å½•
        if project_info.get("has_subagents"):
            src_subagents = project_info["path"] / "subagents"
            dst_subagents = raw_dir / "subagents"
            if dst_subagents.exists():
                shutil.rmtree(dst_subagents)
            shutil.copytree(src_subagents, dst_subagents)

        # é¡¹ç›®ç´¢å¼•æ–‡ä»¶
        index_lines = [
            f"# é¡¹ç›®: {decode_project_path(project_name)}",
            "",
            f"| ä¼šè¯ID | å¤§å° | æœ€åä¿®æ”¹ |",
            f"|--------|------|----------|",
        ]

        for session in sorted(project_info["sessions"], key=lambda s: s["mtime"], reverse=True):
            session_id = session["id"]
            file_key = f"{project_name}/{session_id}"
            file_hash = get_file_hash(session["file"])

            # å¢é‡æ¨¡å¼ï¼šè·³è¿‡æœªå˜åŒ–çš„æ–‡ä»¶
            if mode == "incremental" and file_key in synced_files:
                if synced_files[file_key] == file_hash:
                    skipped_count += 1
                    # ä»ç„¶æ·»åŠ åˆ°ç´¢å¼•
                    mtime_str = datetime.fromtimestamp(session["mtime"]).strftime("%Y-%m-%d %H:%M")
                    size_kb = session["size"] / 1024
                    index_lines.append(
                        f"| [{session_id[:8]}...]({session_id}.md) | {size_kb:.1f}KB | {mtime_str} |"
                    )
                    continue

            # è§£æå¹¶è½¬æ¢
            print(f"  å¤„ç†: {project_display}/{session_id[:8]}...")
            messages = parse_jsonl_file(session["file"])

            if not messages:
                continue

            md_content = format_conversation_md(
                session_id, messages, decode_project_path(project_name)
            )

            # å†™å…¥ Markdown æ–‡ä»¶
            out_file = project_out_dir / f"{session_id}.md"
            out_file.write_text(md_content, encoding="utf-8")

            # å¤åˆ¶åŸå§‹ JSONL æ–‡ä»¶
            shutil.copy2(session["file"], raw_dir / f"{session_id}.jsonl")

            # å¤åˆ¶ä¼šè¯å­ç›®å½•ï¼ˆtool-results ç­‰ï¼‰
            if session.get("has_subdir"):
                src_subdir = project_info["path"] / session_id
                dst_subdir = raw_dir / session_id
                if dst_subdir.exists():
                    shutil.rmtree(dst_subdir)
                shutil.copytree(src_subdir, dst_subdir)

            # æ›´æ–°åŒæ­¥çŠ¶æ€
            synced_files[file_key] = file_hash
            synced_count += 1

            # æ·»åŠ åˆ°ç´¢å¼•
            mtime_str = datetime.fromtimestamp(session["mtime"]).strftime("%Y-%m-%d %H:%M")
            size_kb = session["size"] / 1024
            index_lines.append(
                f"| [{session_id[:8]}...]({session_id}.md) | {size_kb:.1f}KB | {mtime_str} |"
            )

        # å†™å…¥é¡¹ç›®ç´¢å¼•
        index_file = project_out_dir / "ç´¢å¼•.md"
        index_file.write_text("\n".join(index_lines), encoding="utf-8")

    print(f"\nåŒæ­¥: {synced_count} ä¸ªå¯¹è¯, è·³è¿‡: {skipped_count} ä¸ªæœªå˜åŒ–")

    if synced_count == 0 and mode == "incremental":
        print("æ²¡æœ‰æ–°çš„å˜åŒ–éœ€è¦åŒæ­¥ã€‚")
        save_sync_state(state)
        return

    # Git æäº¤å¹¶æ¨é€
    print("æ­£åœ¨æäº¤å¹¶æ¨é€åˆ° GitHub...")
    run_cmd(["git", "add", "-A"], cwd=str(repo_dir))

    # æ£€æŸ¥æ˜¯å¦æœ‰å˜åŒ–
    r = run_cmd(["git", "status", "--porcelain"], cwd=str(repo_dir))
    if not r.stdout.strip():
        print("Git ä»“åº“æ— å˜åŒ–ã€‚")
        save_sync_state(state)
        return

    now_str = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    commit_msg = f"åŒæ­¥å¯¹è¯è®°å½• [{mode}] - {now_str}\n\næ›´æ–° {synced_count} ä¸ªå¯¹è¯"
    run_cmd(["git", "commit", "-m", commit_msg], cwd=str(repo_dir))

    # æ¨é€ï¼ˆå¤„ç†ç©ºä»“åº“é¦–æ¬¡æ¨é€ï¼‰
    r = run_cmd(["git", "push", "-u", "origin", "HEAD:main"], cwd=str(repo_dir), check=False)
    if r.returncode != 0:
        # å°è¯• master åˆ†æ”¯
        run_cmd(["git", "push", "-u", "origin", "HEAD:main"], cwd=str(repo_dir), check=False)

    # ä¿å­˜åŒæ­¥çŠ¶æ€
    state["synced_files"] = synced_files
    save_sync_state(state)

    print(f"\nåŒæ­¥å®Œæˆ! ä»“åº“: https://github.com/{full_repo}")


def show_status():
    """æ˜¾ç¤ºåŒæ­¥çŠ¶æ€ã€‚"""
    machine_id = get_machine_id()
    short_id = get_machine_id_short(machine_id)
    state = load_sync_state()
    projects = scan_projects()

    total_sessions = sum(len(p["sessions"]) for p in projects.values())
    synced_count = len(state.get("synced_files", {}))

    print(f"æœºå™¨ç : {machine_id}")
    print(f"çŸ­æ ‡è¯†: {short_id}")
    print(f"ä¸Šæ¬¡åŒæ­¥: {state.get('last_sync', 'ä»æœªåŒæ­¥')}")
    print(f"é¡¹ç›®æ•°: {len(projects)}")
    print(f"æ€»å¯¹è¯æ•°: {total_sessions}")
    print(f"å·²åŒæ­¥æ•°: {synced_count}")
    print(f"å¾…åŒæ­¥æ•°: {total_sessions - synced_count}")
    print()

    for pname, pinfo in projects.items():
        display = decode_project_path(pname)
        print(f"  ğŸ“ {display} ({len(pinfo['sessions'])} ä¸ªå¯¹è¯)")


def _generate_readme(machine_id, short_id, projects):
    """ç”Ÿæˆä»“åº“ READMEã€‚"""
    total = sum(len(p["sessions"]) for p in projects.values())
    now_str = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    lines = [
        f"# Claude Code å¯¹è¯è®°å½•",
        "",
        f"| å±æ€§ | å€¼ |",
        f"|------|-----|",
        f"| æœºå™¨ç  | `{machine_id}` |",
        f"| çŸ­æ ‡è¯† | `{short_id}` |",
        f"| é¡¹ç›®æ•° | {len(projects)} |",
        f"| å¯¹è¯æ€»æ•° | {total} |",
        f"| æœ€åæ›´æ–° | {now_str} |",
        "",
        "## é¡¹ç›®åˆ—è¡¨",
        "",
    ]

    for pname, pinfo in sorted(projects.items()):
        display = decode_project_path(pname)
        dirname = sanitize_dirname(pname)
        lines.append(f"- [{display}]({dirname}/ç´¢å¼•.md) ({len(pinfo['sessions'])} ä¸ªå¯¹è¯)")

    lines.extend([
        "",
        "---",
        "",
        "*ç”± claude-code-sync-github æŠ€èƒ½è‡ªåŠ¨ç”Ÿæˆ*",
    ])

    return "\n".join(lines)


# ============================================================
# å…¥å£
# ============================================================

def main():
    parser = argparse.ArgumentParser(description="Claude Code å¯¹è¯è®°å½•åŒæ­¥åˆ° GitHub")
    parser.add_argument("--mode", choices=["full", "incremental"], default="incremental",
                        help="åŒæ­¥æ¨¡å¼: full=å…¨é‡, incremental=å¢é‡(é»˜è®¤)")
    parser.add_argument("--init", action="store_true", help="ä»…åˆå§‹åŒ–ä»“åº“")
    parser.add_argument("--status", action="store_true", help="æŸ¥çœ‹åŒæ­¥çŠ¶æ€")
    parser.add_argument("--repo", type=str, default=None, help="è‡ªå®šä¹‰ä»“åº“å")

    args = parser.parse_args()

    if args.status:
        show_status()
        return

    machine_id = get_machine_id()

    if args.init:
        init_repo(machine_id, args.repo)
        return

    sync(mode=args.mode, repo_name=args.repo)


if __name__ == "__main__":
    main()
