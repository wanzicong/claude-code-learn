{
  "video_path": "C:\\Users\\13608\\.claude\\skills\\bilibili-download\\downloads\\重磅！Qwen3 Coder Next发布了，借它聊一下Agent蜂群，今年的一条主线_BV119foBUE7h.mp4",
  "video_name": "重磅！Qwen3 Coder Next发布了，借它聊一下Agent蜂群，今年的一条主线_BV119foBUE7h",
  "duration": 352.246485,
  "segments": [
    {
      "start": 0.0,
      "end": 10.0,
      "text": "大家好,前几天被OpenCloud刷屏了吧,我也说了,那只是个小儿科而已。相信我马上就会有更高级的场景出现。"
    },
    {
      "start": 10.0,
      "end": 18.0,
      "text": "你是想想,如果一声令下就像统了马峰窩一样,有无数密封冲出来给你干活,那场面会是什么呀。"
    },
    {
      "start": 19.0,
      "end": 30.0,
      "text": "而今天凌晨刚刚发布的Kun3CodeNax,我从凌晨就开始进行部署测试了。我判断它将是解锁这个封群系统的一块非常重要的拼图。"
    },
    {
      "start": 31.0,
      "end": 40.0,
      "text": "我十分确定,今年正在开始的一条AI主线,就是复杂编牌和主控加封群的AZN的架构。"
    },
    {
      "start": 41.0,
      "end": 50.0,
      "text": "我引用一下杨直林在前几天一场AMA中说过了一段话,他的意思是高级量数据的增长速度已经赶不上算力增长了。"
    },
    {
      "start": 50.0,
      "end": 68.0,
      "text": "传统的Skilling带来的提升会越来越小。那怎么办呢?我用可以用AZN的Swarm,也就是封群的方式来扩大增加并行的贼震的数量,用人话说,我们不应该总是想着用一个大神模型就把事全干了。"
    },
    {
      "start": 68.0,
      "end": 74.0,
      "text": "大神可以干指挥,做好规划,然后掉用一个封群来解决更复杂的任务。"
    },
    {
      "start": 74.0,
      "end": 83.0,
      "text": "但问题是,封群架构需要什么样的小密封呢?我的观点是,第一要成本地,要能高速并发在本地跑。"
    },
    {
      "start": 83.0,
      "end": 88.0,
      "text": "第二,主控的任务要能在一个上下文中独立完成。"
    },
    {
      "start": 88.0,
      "end": 97.0,
      "text": "第三,它还得有足够强的AZN能独立完成任务。如果有一种模型恰好满足这三个条件呢,那就是今天的主角。"
    },
    {
      "start": 98.0,
      "end": 100.0,
      "text": "Kwin3CodeNext的。"
    },
    {
      "start": 100.0,
      "end": 104.0,
      "text": "先看,第一个条件,去年9月我测试了这个模型的上一个版本。"
    },
    {
      "start": 104.0,
      "end": 111.0,
      "text": "它几乎参入只有3B,生成速度超快,而且96G线存就可以支持它同时运行多个并发。"
    },
    {
      "start": 111.0,
      "end": 114.0,
      "text": "尤其是许多消费机的硬件都能跑起来。"
    },
    {
      "start": 114.0,
      "end": 119.0,
      "text": "再看第二条件,长上下文的性能,这就是它的专长了。"
    },
    {
      "start": 119.0,
      "end": 127.0,
      "text": "如果你用过本地模型一定经历过这种情况,刚开始每秒能输出150个偷肯,到最后慢慢的变成每秒只有10个偷肯。"
    },
    {
      "start": 128.0,
      "end": 131.0,
      "text": "超级卡,这不是你显卡的问题。"
    },
    {
      "start": 131.0,
      "end": 138.0,
      "text": "这是大多数模型处理长文本时候的通病,上下文月长计算量成指数级增长。"
    },
    {
      "start": 138.0,
      "end": 147.0,
      "text": "但Next系列不是这样,它是一种现性注意力架构,随着上下文地增,它的速度摔减会趋于平缓。"
    },
    {
      "start": 147.0,
      "end": 155.0,
      "text": "去年9月我实测了对比Next80B和Kwin330B,短上下文的时候30B的确很快,"
    },
    {
      "start": 155.0,
      "end": 164.0,
      "text": "但超过了50K以后80B开始反超,到了256K上下文的时候80B的速度居然是30B的2.4倍。"
    },
    {
      "start": 164.0,
      "end": 170.0,
      "text": "这意味什么?风群架构中每个小密封都要尝试尖工作,处理大量上下文。"
    },
    {
      "start": 170.0,
      "end": 175.0,
      "text": "CodeNext的长上下文性刚好是气和这个场景的。"
    },
    {
      "start": 175.0,
      "end": 178.0,
      "text": "但这还不够,再看第三个条件,AZ的能力。"
    },
    {
      "start": 178.0,
      "end": 183.0,
      "text": "在技术报告中有关键点,它是专门为AZ哪儿生的。"
    },
    {
      "start": 183.0,
      "end": 186.0,
      "text": "我们不要看明子叫Code,它就是给程序员用的。"
    },
    {
      "start": 186.0,
      "end": 194.0,
      "text": "这种AZ其实更加擅长用带马来解决通用问题,它的大量后训练也是比较是这个目标的。"
    },
    {
      "start": 194.0,
      "end": 202.0,
      "text": "我在实际中体验感觉非常明显,它在CodeCode环境中的表现已经完全不是过去那个版本了。"
    },
    {
      "start": 202.0,
      "end": 207.0,
      "text": "报告里也提到了一些李普的Bandmark,超过这个超过那个,我当然不会全新了。"
    },
    {
      "start": 208.0,
      "end": 214.0,
      "text": "当然要自己测,原本下期的视频是要分享如何做一个新技能叫Cade,也是我的一个刚需场景。"
    },
    {
      "start": 214.0,
      "end": 218.0,
      "text": "我经常跑长时间的任务时,自己就跑去客厅打游戏了。"
    },
    {
      "start": 218.0,
      "end": 223.0,
      "text": "这个Cade技能的作用时,在任务完成后,利用APP通过轰怕的Mini来通知我。"
    },
    {
      "start": 223.0,
      "end": 228.0,
      "text": "老实说,昨天我用KR.5一个ProM的就实现了,我还是挺惊讶的。"
    },
    {
      "start": 228.0,
      "end": 233.0,
      "text": "但是今天CodeNext一个80B的小模型居然也做到了。"
    },
    {
      "start": 233.0,
      "end": 239.0,
      "text": "从结果来看,虽然在图中遇到了一些错误,但最终还是从错误中恢复完成了任务。"
    },
    {
      "start": 239.0,
      "end": 245.0,
      "text": "帮我调查了指定的倡库,完成了代码,还成功了运行,我们来看看成果吧。"
    },
    {
      "start": 245.0,
      "end": 248.0,
      "text": "好了,它又把这个东北话支持了。"
    },
    {
      "start": 248.0,
      "end": 253.0,
      "text": "我们它现在已经都做好了,我们来测试一下。"
    },
    {
      "start": 253.0,
      "end": 260.0,
      "text": "先立创意味大众到公主,今天下三份,一周疲地,可以啊,积存王之秋言。"
    },
    {
      "start": 261.0,
      "end": 267.0,
      "text": "要知道,在去年9月的那个版本,用CodeCode跑简单的任务还有点勉强。"
    },
    {
      "start": 267.0,
      "end": 277.0,
      "text": "但是现在只用一条ProM的同一个上下文内,它会灵活的使用Code的各种工具,分解任务从错误中恢复,并且始终记得任务目标。"
    },
    {
      "start": 277.0,
      "end": 283.0,
      "text": "这些在AZN时代都至关重要。CodeNext的表现非常不错。"
    },
    {
      "start": 283.0,
      "end": 289.0,
      "text": "而且千万不要忘了,它是256K的上下文,这个是非常使用的。"
    },
    {
      "start": 289.0,
      "end": 296.0,
      "text": "我还尝试在它做任务的涂中,同时开启了另外的两个任务,速度完全没有受到影响。"
    },
    {
      "start": 296.0,
      "end": 302.0,
      "text": "如果一个AZN有盖绿完成任务,我们就可以用多个赋本来提高任务的成功率。"
    },
    {
      "start": 302.0,
      "end": 306.0,
      "text": "这也是用算力换结果的SKaleOut的方法论。"
    },
    {
      "start": 306.0,
      "end": 308.0,
      "text": "所以说我们要的小密封应该是什么样?"
    },
    {
      "start": 308.0,
      "end": 316.0,
      "text": "能在消费机设备上跑,常上下文性能衰减慢,有教强的AZN能力,窗口大能独立完成紫任务。"
    },
    {
      "start": 316.0,
      "end": 320.0,
      "text": "这就是实现风群的我想要的那块拼图。"
    },
    {
      "start": 320.0,
      "end": 327.0,
      "text": "当然了,很多程序员会干,会说它编程能力差,你又没有搞错80B的模型,拿它去编程。"
    },
    {
      "start": 327.0,
      "end": 335.0,
      "text": "这种模型如果放在企业内部是绝佳的,它能做自动化,能做提效工具,能做AZN的调用器,"
    },
    {
      "start": 335.0,
      "end": 338.0,
      "text": "这企业内部的一个非常不错的选择。"
    },
    {
      "start": 338.0,
      "end": 348.0,
      "text": "最近我正在把我的AZN的框架做更新,让它支持KMKL.5来做编排,让自己AZN在不同的容器高并放的执行。"
    },
    {
      "start": 348.0,
      "end": 352.0,
      "text": "大家等我后续更新吧,以上就是本期全部的内容了。谢谢大家。"
    }
  ],
  "language": "zh",
  "source": "whisper"
}